---
title: SVM(Support Vector Machine)
date: 2024-04-09 19:30:00 +09:00
categories: [cs, 기계 학습]
---

# SVM
![SVM_01](https://github.com/patchpark/patchpark.github.io/assets/116805893/3cba32e6-8dca-444b-bd38-cbe16178925f)


위의 그림과 같이 데이터들을 두 클래스로 구분하는 다양한 직선을 그어 볼 수 있다. 이때 error를 최소화 하기 위해서는 어떤 직선을 채택해야할까? 이 때 사용할 수 있는 방법이 SVM이다.
<br><br>
![SVM_02](https://github.com/patchpark/patchpark.github.io/assets/116805893/049f1682-b25c-4af8-b943-59393cbc2124)


그어진 선을 y=0이라고 했을 때, support vectors 란 y=0에 가장 가까이 존재하는 데이터들이다. support vector와 그어진 선 사이의 거리를 margin이라고 하며, 양쪽 margin의 합이 최대가 될 때 error가 최소화 된다. y = wx + b라고 가정하면, 몇가지 성질이 존재함을 알 수 있는데, 
1) support vector의 값은(x1 , 1), (x2 , -1)을 만족한다.
2) a지점에 존재하는 데이터 x3에 대하여 wx3+ b >= 1을 만족한다.
3) b지점에 존재하는 데이터 x4에 대하여 wx4+ b <= -1을 만족한다.
4) support vector를 제외한 나머지 데이터값들은 직선을 결정하는데 있어 쓰이지 않는다.
5) margin의 크기는 그림과 같이 2/||W||2이다.
<br><br>
![SVM_03](https://github.com/patchpark/patchpark.github.io/assets/116805893/bdf660a9-391f-487f-8dba-d62ba20dafc0)
과 같은 과정을 통해 만족하는 직선을 구할 수 있다.

# SVM의 확장

### 다변수와 다분류
![SVM_04](https://github.com/patchpark/patchpark.github.io/assets/116805893/67841d21-e385-450e-b19a-443d0e581e1a)
<br><br>
위의 식과 같이 변수가 여러개인 식으로 확장할 수도 있다.

또한 구분하고 싶은 대상의 개수가 2개가 아니라 N개일 경우, SVM을 N-1번 반복하여 각 차례에서 a와 나머지, 나머지 중 b와 나머지...의 과정을 통해 2개보다 많은 대상도 분류가 가능하다.

### Kernel Method

어떠한 두 클래스가 직선으로는 구분이 되지 않는 상황이 존재할 수 있다. 이때 Kernel Method를 적절하게 사용하면 어떤 두 클래스도 직선으로 구분이 가능해진다. 단, 딥러닝과 다르게 SVM에서는 사용자가 적절하게 Kernel Method를 수행해주어야 한다. 아래는 Kernel Method의 대략적인 동작 방식이다.
<br><br>
![SVM_05](https://github.com/patchpark/patchpark.github.io/assets/116805893/b81ce359-e85b-415d-93d7-8e628159398c)