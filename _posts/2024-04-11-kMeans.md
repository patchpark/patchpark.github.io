---
title: kMeans
date: 2024-04-11 18:30:00 +09:00
categories: [cs, 기계 학습]
---

# k-Means란

k-means는 비지도 학습 방법이며, n개의 데이터를 k개의 집단으로 묶는 알고리즘이다. 예를 들어 어떤 의류 회사에서 신상 옷을 만들려고 하고 있고, 옷을 S, M, L 세가지 사이즈로 구분하려고 한다. 이때, 회사에서는 고객들의 허리 사이즈 데이터를 적절히 3가지 그룹으로 분류하여 각 집단의 평균치를 옷의 사이즈로 출시하려고 할 것이다. 이 때 사용할 수 있는 방법이 k-means인 것이다.

# k-Means의 작동 방식

k = 2 인 상황이라고 가정하면, 데이터 중 랜덤하게 두개의 데이터(centroid)를 선택한다. 나머지 데이터들에 대해 두개의 centroid 중 더 가까운 그룹으로 묶는다. 그룹에 속한 점들의 중점을 다시 계산하고, 계산된 중점을 centroid로 설정해 다시 위의 과정을 반복한다. 진행하다 중점의 좌표 변화가 일정 이상 작아지게 되면 학습을 종료한다. 아래는 과정을 그림으로 나타낸 것이다.

![kMeans_01](https://github.com/patchpark/patchpark.github.io/assets/116805893/1ce4b5e2-904a-4326-8ce7-ee384a772b38)

# k-Means의 단점
k-Means는 간단하고 빠른 동시에, 제법 좋은 성능을 보여주지만 몇가지 단점이 존재한다.

먼저, k의 결정이다. 지도학습이였던 kNN의 경우, 교차 검증(cross validation)을 통해 확인이 가능했던 것과 달리, 비지도 학습인 k-Means는 label이 없는 비지도 학습임으로 교차 검증을 사용할 수 없다. 각 k에 대해, 그룹의 중앙값과 그 그룹에 속한 데이터들의 거리(SSE)를 전부 더한다. k=1(모든 데이터가 같은 그룹)일 경우 SSE값의 합이 제일 커질 것이며, k=n(모든 데이터가 그룹)일 경우 SSE값의 합은 제일 작아질 것이지만 grouping의 의미가 없을 것이다. 이처럼 SSE값 자체가 의미 있는 것은 아님을 알 수 있다. k에 대하여 SSE값의 합을 모두 구해 그래프로 그리면 아래와 같이 나오는데, 이때 error가 많이 줄어들다가 적게 줄어드는 구간의 k를 채택한다. 꺽이는 구간이 팔꿈치를 닮아 Elbow method라고 부른다.

![kMeans_02](https://github.com/patchpark/patchpark.github.io/assets/116805893/14a7aaf0-8d66-4b46-979c-ba9d9d8379fa)


두번째 단점은 k-Means 학습의 결과가 처음 랜덤으로 잡은 중앙값에 영향을 받는다는 것이다. 처음 고른 중앙값에 따라 학습의 결과가 달리 나올 수 있다.

마지막 단점은 outliers(예외)에 취약하다는 것이다. 그룹핑 된 데이터들의 좌표의 평균으로 중점을 선택하는 만큼 예외에 있어 민감히 반응한다.
![kMeans_03](https://github.com/patchpark/patchpark.github.io/assets/116805893/47c32fac-cd39-4ad9-88c7-47a58300d046)

위의 그림과 같이 그림 2처럼 평균 대신 중앙값을 사용하여 예외에 대한 취약점을 어느정도 개선할 수 있다.

# 그 외
비선형적으로 존재하는 데이터에 대하여 k-means역시 kernel methods를 통해 grouping이 가능하다.

[kernel method](https://patchpark.github.io/posts/SVM) 참조